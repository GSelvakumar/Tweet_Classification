{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCojr-BkuujO"
   },
   "source": [
    "## Understanding Natural Language Processing\n",
    "\n",
    "NLP has the goal of derived information out of natural language (could be sequences text or speech). Another common term for NLP problems is sequence to sequence problems (seq2seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4w8cgDLu9d9"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xJK0r0jiwRFp"
   },
   "outputs": [],
   "source": [
    "from helper_functions import unzip_data, plot_loss_curves, create_tensorboard_callback, compare_historys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8wI_mrMx6ea"
   },
   "source": [
    "## Visualizing the Text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WvSHQuta0xyu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"nlp_getting_started/train.csv\")\n",
    "test_df = pd.read_csv(\"nlp_getting_started/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "dMug5GB70473",
    "outputId": "2fac2789-755e-4858-b0bb-74f4f04f4936"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "gVFKBC6R1IUj",
    "outputId": "d1dbcc4d-902e-443a-a6aa-d79b65a84e47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in response to trauma Children of Addicts develop a defensive self - one that decreases vulnerability. (3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting one data sample\n",
    "train_df[\"text\"][6845]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "oRhaKC-O12YA",
    "outputId": "48666d5c-5242-4299-c5e5-21a7090665e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling the data so that the supervised model won't learn any patterns to follow the prediction\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VokBe-_2M3x",
    "outputId": "332e093d-d2ce-4156-edb0-a7cea7b83edb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of examples on the target class\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypCVFJ0X3Erb",
    "outputId": "2215855e-2e6c-45ea-e629-eb3a909b5bad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LnVOzkeH42L9",
    "outputId": "e80ba1b8-e3f6-4ccb-b5f9-d6e2d5a34c97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Value: 0 (not real disaster)\n",
      "Text Value:\n",
      "@ArianaGrande I literally walked out of the concert and screamed MY SOUL HAS BEEN BLESSED\n",
      "\n",
      "---\n",
      "\n",
      "Target Value: 0 (not real disaster)\n",
      "Text Value:\n",
      "@RosemaryTravale Do we all use the same weapon? 'cause we might be screwed XD\n",
      "\n",
      "---\n",
      "\n",
      "Target Value: 0 (not real disaster)\n",
      "Text Value:\n",
      "Stretcher brought out for Vampiro. Cut to commercial isn't a good sign. #UltimaLucha #LuchaUnderground\n",
      "\n",
      "---\n",
      "\n",
      "Target Value: 1 (real disaster)\n",
      "Text Value:\n",
      "Young children among those rescued from capsized boat off Libya http://t.co/Kot9zVD2H7 via @IrishTimesWorld\n",
      "\n",
      "---\n",
      "\n",
      "Target Value: 1 (real disaster)\n",
      "Text Value:\n",
      "Injuries Illnesses and Fatalities Latest Numbers : http://t.co/1uo1aTrbbJ\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize the random samples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5) # less the length so the rand won't exceed it\n",
    "for value in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "  # itertuples are used to iterate over the dataframe rows and return them as tuples.\n",
    "  _, text, target = value\n",
    "  print(f\"Target Value: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "  print(f\"Text Value:\\n{text}\\n\")\n",
    "  print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ja6afGutuJj"
   },
   "source": [
    "## Spliting Data into Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HXqjNY6zty88"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5audtDkpuXaA"
   },
   "outputs": [],
   "source": [
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled['text'].to_numpy(),\n",
    "                                                                              train_df_shuffled['target'].to_numpy(),\n",
    "                                                                              test_size=0.1, # 10% of the train data to be test data\n",
    "                                                                              random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WaAtsqzqvQnO",
    "outputId": "0aec2df5-b55a-4b76-c119-b115a64753a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 762, 6851, 762)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(val_sentences), len(train_labels), len(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFgWTex2vg-M"
   },
   "source": [
    "## Converting Text into Numbers\n",
    "\n",
    "Before building the model need to convert the text into numbers using:\n",
    "\n",
    "1. Tokenization - directly map a token to a number\n",
    "2. Embedding - create a matrix of feature vector for each token(the size of the feature vector can be defined and this embedding can be learned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRxeO5cEi3l7"
   },
   "source": [
    "### Text Vectorization - Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RCCTtPe1jGCe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DgGMJl7QtHN9"
   },
   "outputs": [],
   "source": [
    "# Use the default TextVectorization parameters\n",
    "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (automatically add <oov>)\n",
    "                                    standardize='lower_and_strip_punctuation',\n",
    "                                    split='whitespace',\n",
    "                                    ngrams=None, # create groups of n-words\n",
    "                                    output_mode=\"int\", # how to map tokens to numbers\n",
    "                                    output_sequence_length=None, # how long do you want your sequences to be\n",
    "                                    #pad_to_max_tokens=True # pad the feature axis which are less the max token axis, can be used only when max_tokens is mentioned\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1OyUtNG-e0T",
    "outputId": "12af596d-aa57-470a-f67d-7c032a5cea64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@mogacola', '@zamtriossu', 'i', 'screamed', 'after', 'hitting', 'tweet']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WueEMjRTAFQK",
    "outputId": "15cfc3f5-24fc-40bc-8b8e-dd0c926cf265"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ywDXtKogAIhU",
    "outputId": "20302716-cc47-40d6-bb71-5c63f7ae0a15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102087"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the average number of tokens (words) in the training tweets\n",
    "round(sum([len(i.split()) for i in train_sentences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_YCnpzia27K",
    "outputId": "d79b63b1-cc00-4206-c3f2-6b29e2d5de3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sum([len(i.split()) for i in train_sentences]) / len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "u0G2LDfMa_0C"
   },
   "outputs": [],
   "source": [
    "# Setup Text Vectorization Variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15 # max length the sequences will be (e.g. how many words from a tweet does a model see?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "e8jFxiZ6gy9_"
   },
   "outputs": [],
   "source": [
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode='int',\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "IucKmhmfhcPj"
   },
   "outputs": [],
   "source": [
    "# fit the text vectorizer to the training text\n",
    "\"\"\"\n",
    "Computes a vocabulary of string terms from tokens in a dataset. Calling adapt() on \n",
    "Text Vectorization layer is an alternative to passing in a precomputed vocabulary\n",
    "on construction via the vocabulary argument. A Text Vectorization layer should \n",
    "should always be either adapted over a dataset or supplied with a vocabulary.\n",
    "\"\"\"\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgn55fnwwQa1",
    "outputId": "f7b74106-5d2d-491d-c5ac-6b95eb2cc51d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample a sentence and tokenize it\n",
    "sample_sentence = \"There's a flood in my street!\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-EyLCq6z916",
    "outputId": "6f02be70-c766-468c-f88e-d05f8dd1f8f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: \n",
      " Wow Crackdown 3 uses multiple servers in multiplayer?!?! U can destroy whole buildings?!?! #copped \n",
      "\n",
      " Vectorized Text: \n",
      " [[ 970 3966  118 2626 2851 4659    4 3606  142   71  305  292   95    1\n",
      "     0]]\n"
     ]
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "random_sentence = random.choice(train_sentences)\n",
    "vectorize_sentence = text_vectorizer([random_sentence])\n",
    "print(f\"Original Text: \\n {random_sentence} \\n\\n Vectorized Text: \\n {vectorize_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "i42frtoi070M"
   },
   "outputs": [],
   "source": [
    "# Get Unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary() # get all the unique words from the training data\n",
    "top_5_words = words_in_vocab[:5] # get the most common words\n",
    "bottom_5_words = words_in_vocab[-5:] # get the least common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwdELMl525QR",
    "outputId": "48e703bf-5e4f-42b8-808c-3db5a26a1a8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"5 most common words: {top_5_words}\")\n",
    "print(f\"5 least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUKgwNe43VyT"
   },
   "source": [
    "## Creating an Embedding Using the Embedding Layer\n",
    "\n",
    "Turns positive integers into dense vectors of fixed size\n",
    "\n",
    "* `input_dim` - the size of the vocabulary\n",
    "* `output_dim` - the size of the output embedding vector, for example, a value of 100 would mean each token gets represented by a vector 100 long\n",
    "* `input_length` - length of the sequences being passed to the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29nH9c3tHA1j",
    "outputId": "b3c44bbd-281b-4984-e61c-b8644eb53f61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x7f96f1794610>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128, # output shape\n",
    "                             embeddings_initializer='uniform',\n",
    "                             input_length=max_length # how long is each input\n",
    "                             )\n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tMssW_4Iobf",
    "outputId": "56a46723-8811-48d4-df97-c24e471251a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " @nycdivorcelaw TRUMP IS A CLIMATE DENIER- algae bloom in the pacific from calif to alska- seeweed in caribean forest fires- SNOWBALL INHOFE \n",
      "\n",
      "Embedded Version: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.00191194, -0.02992626,  0.02174624, ...,  0.00302727,\n",
       "         -0.00730379,  0.0346303 ],\n",
       "        [ 0.04259581, -0.02224317, -0.02177726, ...,  0.0322105 ,\n",
       "         -0.0227069 ,  0.00523484],\n",
       "        [-0.04626394, -0.0463458 , -0.02324349, ..., -0.0318409 ,\n",
       "         -0.01115724,  0.00752554],\n",
       "        ...,\n",
       "        [ 0.00794456,  0.00235112,  0.0302866 , ...,  0.02430489,\n",
       "         -0.02236264,  0.02515768],\n",
       "        [ 0.0133695 ,  0.0238965 ,  0.04438256, ..., -0.02206298,\n",
       "          0.01555556, -0.02190062],\n",
       "        [-0.00191194, -0.02992626,  0.02174624, ...,  0.00302727,\n",
       "         -0.00730379,  0.0346303 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a Random sentence from the training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "\n",
    "print(f\"Original Text:\\n {random_sentence} \\n\\nEmbedded Version: \")\n",
    "\n",
    "# Embed the random sentence (turn positive integers into dense vectors of fixed size)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtELrmQeHom4"
   },
   "source": [
    "every single tweet are now in the form of 128 dense vectors. Always using the size as a divisible of 8 will increase the computation speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8g4sJC5rJTUq",
    "outputId": "c6ffddb5-59d0-4eae-b51a-d278a2eb9b78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('@nycdivorcelaw TRUMP IS A CLIMATE DENIER- algae bloom in the pacific from calif to alska- seeweed in caribean forest fires- SNOWBALL INHOFE',\n",
       " <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([-1.9119382e-03, -2.9926265e-02,  2.1746244e-02, -1.8007528e-02,\n",
       "        -4.0272843e-02, -3.4565020e-02, -1.0318302e-02, -4.0053703e-02,\n",
       "         1.9137982e-02,  3.2780077e-02,  1.3430826e-03, -7.0409887e-03,\n",
       "         2.5820959e-02, -3.1653523e-02, -4.8954990e-02,  3.4493852e-02,\n",
       "        -3.1538270e-02,  3.0330662e-02, -2.5676036e-02, -3.3657540e-02,\n",
       "        -2.7790248e-02,  4.4952396e-02, -1.2484372e-02, -1.6486265e-02,\n",
       "        -1.2290012e-02,  9.5976703e-03, -4.9855113e-02, -2.1670688e-02,\n",
       "         4.5809280e-02, -2.2477819e-02, -4.7177188e-03, -3.7623264e-02,\n",
       "         3.9073478e-02, -8.3962828e-04,  4.2126287e-02, -1.2835443e-02,\n",
       "         1.5872467e-02,  4.8381519e-02, -3.1540595e-02,  2.0862930e-03,\n",
       "         5.1646344e-03,  4.6662662e-02, -2.8603151e-04, -3.1220628e-02,\n",
       "         4.1717265e-02, -4.9107254e-02, -2.1822035e-02, -1.9112850e-02,\n",
       "        -3.5421073e-02,  3.7669126e-02, -3.8004316e-02, -2.3492945e-02,\n",
       "         3.7225869e-02,  4.8701536e-02,  4.0603425e-02, -2.1273924e-02,\n",
       "         3.2275293e-02, -6.5696612e-03, -1.8823612e-02,  5.4363236e-03,\n",
       "         3.6903109e-02, -2.0382404e-03, -8.7333322e-03, -4.6614386e-02,\n",
       "         3.2446269e-02,  3.5012636e-02, -1.6863156e-02, -2.0226216e-02,\n",
       "         4.9320150e-02,  3.7245248e-02,  1.1468768e-02, -4.2058669e-02,\n",
       "        -3.2298110e-02,  4.7313761e-02,  7.2375312e-03,  1.6211342e-02,\n",
       "         2.9373836e-02,  2.3360241e-02, -3.4215737e-02,  3.3203449e-02,\n",
       "         3.8388703e-02,  1.3859395e-02, -1.6507626e-02,  3.0457903e-02,\n",
       "         1.9432332e-02,  2.7569644e-03,  2.9384110e-02, -3.9933097e-02,\n",
       "         4.4160709e-03,  3.7499141e-02, -2.3189411e-03, -3.6479224e-02,\n",
       "        -4.6174195e-02, -5.5155866e-03, -2.2477007e-02,  3.3161167e-02,\n",
       "        -3.2879591e-02, -2.2236396e-02,  2.8698448e-02, -1.7108060e-02,\n",
       "         6.7941546e-03,  2.0423420e-03, -5.6549422e-03,  8.7641105e-03,\n",
       "         8.0050938e-03,  4.3825042e-02,  4.3396082e-02,  3.8575381e-05,\n",
       "        -1.1449646e-02,  2.9617548e-04,  5.2160248e-03,  4.9670484e-02,\n",
       "        -2.3011565e-02,  3.5915326e-02,  3.6677830e-03,  3.7480067e-02,\n",
       "         1.7159846e-02, -1.4918923e-02,  2.1689784e-02, -2.0077515e-02,\n",
       "         5.8258660e-03, -4.6326067e-02,  2.2604335e-02,  3.8925041e-02,\n",
       "         2.0022299e-02,  3.0272715e-03, -7.3037855e-03,  3.4630302e-02],\n",
       "       dtype=float32)>,\n",
       " TensorShape([128]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking out single token embedding\n",
    "random_sentence, sample_embed[0][0], sample_embed[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4eWi479JgAr"
   },
   "source": [
    "## Modelling a Text Dataset\n",
    "\n",
    "- Model 0: Naive Bayes - sklearn(baseline)\n",
    "- Model 1: Feed-Forward Neural Network(dense model)\n",
    "- Model 2: LSTM Model (RNN)\n",
    "- Model 3: GRU Model (RNN)\n",
    "- Model 4: Bidirectional-LSTM Model (RNN)\n",
    "- Model 5: 1D Conventional Neural Network (CNN)\n",
    "- Model 6: Tensorflow Hub Pretrained Feature Extractor (using Transfer Learning for NLP)\n",
    "- Model 7: Same as Model 6 with 10% of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c6OkBu6MFIS"
   },
   "source": [
    "## Model 0: Getting a Baseline Model\n",
    "\n",
    "It's important to create a baseline model to attain a benchmark for future experiments/models to build upon. It's common practice to use non-DL algorithms as a baseline because of their speed and then later using DL to see if it can be improved upon them.\n",
    "\n",
    "Here the Baseline created is - SkLearn's Multinomial Naive Bayes using the TF-IDF formula to convert the words into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tDatsBODUq-u",
    "outputId": "6626cd10-8ef6-479b-91a0-b5a21104a718"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create Tokenization and Modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), # convert words into numbers using tfidf\n",
    "    (\"clf\", MultinomialNB()) # model the text, clf-classification\n",
    "])\n",
    "\n",
    "# Fit the Pipeline to Training Data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1L2CUpxCW44A",
    "outputId": "55f86954-4cdb-45a0-94fb-53036d615751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Baseline Model achieves an accuracy of: 79.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Baseline Model\n",
    "baseline_score = model_0.score(test_sentences, test_labels)\n",
    "print(f\"The Baseline Model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I32xU_HlYgTN",
    "outputId": "d7b64c94-bfc8-4f1f-f7e9-06e27c303668"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions\n",
    "baseline_preds = model_0.predict(test_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "4nLXHa8Yk9I8"
   },
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculate model accuracy, precision, recall and f1 score of a binary\n",
    "  classification model.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred)*100\n",
    "\n",
    "  # Calculate model precision, recall and f1-score using weighted average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "  model_results={\"accuracy\": model_accuracy,\n",
    "                 \"precision\": model_precision,\n",
    "                 \"recall\": model_recall,\n",
    "                 \"f1\": model_f1}\n",
    "\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iocHeLablID9",
    "outputId": "320b07e2-8a9d-40b1-d092-b04b911e26a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Baseline results\n",
    "baseline_results = calculate_results(y_true=test_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1m6Fqrwo2ye"
   },
   "source": [
    "## Model 1: A Simple Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "xha83tYxjBEf"
   },
   "outputs": [],
   "source": [
    "# Create a tensorboard callback (need to create a new one for each model)\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Creating a directory to save tensorboard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "45fTHFDFjKV7"
   },
   "outputs": [],
   "source": [
    "# Build Model with a Functional API\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional strings\n",
    "x = text_vectorizer(inputs) # turn the input text into numbers\n",
    "x = embedding(x) # create a embedding of the numberized inputs\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # Create the output layer, want binary outputs so using sigmoid activation function\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvJQmvbklLQ3",
    "outputId": "8717511e-fc07-43e1-8705-9e03cc3c37a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 15, 1)             129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "m4k-QvLDlNbE"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipY0n_Gzmhdo"
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model_1_history = model_1.fit()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
